# Upgrade SDKs (optional; restart kernel after this cell if they upgrade)
# !pip install --upgrade boto3 botocore

import os
import io
import re
import json
import glob
import time
import shutil
import logging
import xml.etree.ElementTree as ET
from datetime import datetime
from os import listdir, makedirs
from os.path import isfile, join

import boto3
from botocore.exceptions import ClientError

from IPython.display import HTML, display, JSON
from PIL import Image, ImageDraw, ImageFont

# -------------------------
# Config & sanity checks
# -------------------------
# Default region if not set in your environment/credentials.
DEFAULT_REGION = os.environ.get("AWS_DEFAULT_REGION") or "us-east-1"

# Ensure boto3 uses a region
mySession = boto3.session.Session(region_name=DEFAULT_REGION if not boto3.session.Session().region_name else None)
awsRegion = mySession.region_name or DEFAULT_REGION
print("AWS Region:", awsRegion)

rekognition = mySession.client('rekognition', region_name=awsRegion)
s3_client  = mySession.client('s3', region_name=awsRegion)
s3_res     = mySession.resource('s3', region_name=awsRegion)

# IMPORTANT: set your Custom Labels bucket name (the one CL created for you)
rek_cl_default_bucket = "<YOUR-REK-CL-BUCKET>"
assert rek_cl_default_bucket and "<" not in rek_cl_default_bucket, "Set rek_cl_default_bucket to your actual bucket name!"

# Polling intervals / timeouts (tune as you like)
POLL_CREATE_DATASET_SEC = 60      # originally 120s
POLL_START_MODEL_SEC    = 120     # originally 300s
POLL_TRAIN_MODEL_SEC    = 300     # originally 1800s
TIMEOUT_CREATE_DATASET  = 3600    # 1h
TIMEOUT_START_STOP      = 3600    # 1h
TIMEOUT_TRAIN           = 36000   # 10h

# -------------------------
# Download Stanford Dogs
# -------------------------
stanford_dog_dataset_image_url = "http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar"
stanford_dog_dataset_annotation_url = "http://vision.stanford.edu/aditya86/ImageNetDogs/annotation.tar"

!mkdir -p ./stanford_dog_dataset/images_tar
!mkdir -p ./stanford_dog_dataset/images
!mkdir -p ./stanford_dog_dataset/annotation_tar
!mkdir -p ./stanford_dog_dataset/annotation

# If files already exist, skip downloading to save time
if not os.path.exists("./stanford_dog_dataset/images_tar/images.tar"):
    !curl -L "{stanford_dog_dataset_image_url}" --output ./stanford_dog_dataset/images_tar/images.tar
else:
    print("images.tar already present, skipping download.")

if not os.path.exists("./stanford_dog_dataset/annotation_tar/annotation.tar"):
    !curl -L "{stanford_dog_dataset_annotation_url}" --output ./stanford_dog_dataset/annotation_tar/annotation.tar
else:
    print("annotation.tar already present, skipping download.")

# Extract (idempotent)
!tar -xf ./stanford_dog_dataset/images_tar/images.tar -C ./stanford_dog_dataset/images --no-same-owner
!tar -xf ./stanford_dog_dataset/annotation_tar/annotation.tar -C ./stanford_dog_dataset/annotation --no-same-owner

# -------------------------
# Helper: parse Stanford XML → GT manifest
# -------------------------
def safe_truetype(font_path_candidates=("DejaVuSans.ttf", "/usr/share/fonts/dejavu/DejaVuSans.ttf", "/System/Library/Fonts/Supplemental/Arial Unicode.ttf")):
    for path in font_path_candidates:
        try:
            return ImageFont.truetype(path, 10)
        except Exception:
            continue
    return ImageFont.load_default()

def generate_manifest_file(stanford_image_paths, final_manifest_file_path):
    """
    Takes a list of local image file paths from Stanford Dogs and writes a single GroundTruth manifest JSONL.
    We derive each image's annotation XML by transforming the path and then locating the XML via glob.
    """
    final_lines = []
    class_dict = {}

    for img_path in stanford_image_paths:
        # Example:
        # ./stanford_dog_dataset/images/Images/n02090379-redbone/n02090379_1799.jpg
        # → annotation dir:
        annot_dir = img_path.replace('/images/Images/', '/annotation/Annotation/').replace('.jpg', '')

        # Each annotation is typically in a folder with the same base name; XML is inside it.
        # Try a few possibilities robustly:
        xml_candidates = []
        if os.path.isdir(annot_dir):
            xml_candidates = glob.glob(os.path.join(annot_dir, "*.xml"))
        else:
            # Sometimes the XML might be directly at that path with .xml
            xml_guess = annot_dir + ".xml"
            if os.path.exists(xml_guess):
                xml_candidates = [xml_guess]

        if not xml_candidates:
            print(f"[WARN] No XML found for {img_path} at/under {annot_dir}. Skipping.")
            continue

        xml_path = xml_candidates[0]
        with open(xml_path, "r") as f:
            xml_text = f.read()

        root = ET.fromstring(xml_text)

        img_size = {}
        img_nm = None

        for child in root:
            if child.tag == 'filename':
                img_nm = child.text
            elif child.tag == 'size':
                for elem in child.iter():
                    if elem.tag == 'width':
                        img_size["width"] = int(elem.text)
                    if elem.tag == 'height':
                        img_size["height"] = int(elem.text)
                    if elem.tag == 'depth':
                        img_size["depth"] = int(elem.text)

        annotations = []
        objects = []
        class_map = {}
        objcts = root.findall('object') or []

        for objct in objcts:
            annotation = {}
            confidence = {}
            class_nm = None
            class_id = None
            xmin = ymin = xmax = ymax = None

            for elem in objct.iter():
                if elem.tag == 'name':
                    class_nm = elem.text.strip()
                    class_id = class_dict.get(class_nm)
                    if class_id is None:
                        class_id = len(class_dict)
                        class_dict[class_nm] = class_id

                if elem.tag == 'bndbox':
                    for se in elem.iter():
                        if se.tag == 'xmin':
                            xmin = int(float(se.text))
                        if se.tag == 'ymin':
                            ymin = int(float(se.text))
                        if se.tag == 'xmax':
                            xmax = int(float(se.text))
                        if se.tag == 'ymax':
                            ymax = int(float(se.text))

            if None not in (xmin, ymin, xmax, ymax):
                annotation["class_id"] = class_id
                annotation["top"] = ymin
                annotation["left"] = xmin
                annotation["width"] = xmax - xmin
                annotation["height"] = ymax - ymin
                annotations.append(annotation)

                confidence["confidence"] = 1
                objects.append(confidence)

                class_map[class_id] = class_nm

        bbx = {"image_size": [img_size], "annotations": annotations}
        bbx_mtdata = {
            "objects": objects,
            "class-map": class_map,
            "type": "groundtruth/object-detection",
            "human-annotated": "yes",
            "creation-date": datetime.today().strftime('%Y-%m-%dT%H:%M:%S'),
            "job-name": "testjob"
        }

        # IMPORTANT: The source-ref must point to the exact S3 location you will upload to.
        # We'll upload images to: s3://{rek_cl_default_bucket}/stanford_dog_dataset/dataset/<filename>.jpg
        # So the manifest references that.
        source_ref = f's3://{rek_cl_default_bucket}/stanford_dog_dataset/dataset/{os.path.basename(img_path)}'

        single = {
            "source-ref": source_ref,
            "bounding-box": bbx,
            "bounding-box-metadata": bbx_mtdata
        }

        final_lines.append(json.dumps(single) + "\n")

    with open(final_manifest_file_path, "w") as out:
        out.writelines(final_lines)

    print(f"Wrote manifest with {len(final_lines)} lines → {final_manifest_file_path}")

# -------------------------
# Choose 3 classes; keep 1 image each for holdout
# -------------------------
classes_to_be_trained = [
    "n02090379-redbone",
    "n02099601-golden_retriever",
    "n02107142-Doberman"
]

holdoutset_list = {
    "n02090379-redbone"     : "./stanford_dog_dataset/images/Images/n02090379-redbone/n02090379_1799.jpg",
    "n02099601-golden_retriever" : "./stanford_dog_dataset/images/Images/n02099601-golden_retriever/n02099601_3388.jpg",
    "n02107142-Doberman"    : "./stanford_dog_dataset/images/Images/n02107142-Doberman/n02107142_385.jpg",
    # unseen class for sanity check
    "n02091831-Saluki"      : "./stanford_dog_dataset/images/Images/n02091831-Saluki/n02091831_3909.jpg"
}

dataset_list = []

makedirs("./stanford_dog_dataset/holdout", exist_ok=True)
makedirs("./stanford_dog_dataset/dataset", exist_ok=True)

for class_nm in classes_to_be_trained:
    existing_path = f'./stanford_dog_dataset/images/Images/{class_nm}'
    onlyfiles = [join(existing_path, f) for f in listdir(existing_path) if isfile(join(existing_path, f)) and f.lower().endswith(".jpg")]

    # Remove holdout if present
    if holdoutset_list[class_nm] in onlyfiles:
        onlyfiles.remove(holdoutset_list[class_nm])

    for dataset_file_pth in onlyfiles:
        dataset_list.append(dataset_file_pth)
        dest_dataset_image_path = f'./stanford_dog_dataset/dataset/{os.path.basename(dataset_file_pth)}'
        if not os.path.exists(dest_dataset_image_path):
            shutil.copy(dataset_file_pth, dest_dataset_image_path)

# Create manifest for training images
generate_manifest_file(dataset_list, './stanford_dog_dataset/dataset/dataset.manifest')

# Copy holdout images locally
for class_nm, file_path in holdoutset_list.items():
    dest_holdout_image_path = f'./stanford_dog_dataset/holdout/{class_nm.split("-")[-1]}.jpg'
    if not os.path.exists(dest_holdout_image_path):
        shutil.copy(file_path, dest_holdout_image_path)

# -------------------------
# Upload dataset + holdout to your Rekognition CL bucket
# -------------------------
# Note: Use {rek_cl_default_bucket} (Python var) in IPython shell command
!aws s3 cp ./stanford_dog_dataset/dataset/  "s3://{rek_cl_default_bucket}/stanford_dog_dataset/dataset/"  --recursive --quiet
!aws s3 cp ./stanford_dog_dataset/holdout/  "s3://{rek_cl_default_bucket}/stanford_dog_dataset/holdout/"  --recursive --quiet

# -------------------------
# Create project
# -------------------------
cl_project = rekognition.create_project(ProjectName='stanford_dogs_dataset_project')
display(JSON(cl_project))

# -------------------------
# Create TRAIN dataset from manifest
# -------------------------
cl_dataset_train = rekognition.create_dataset(
    DatasetSource={
        'GroundTruthManifest': {
            'S3Object': {
                'Bucket': rek_cl_default_bucket,
                'Name': 'stanford_dog_dataset/dataset/dataset.manifest'
            }
        }
    },
    DatasetType='TRAIN',
    ProjectArn=cl_project['ProjectArn']
)
display(JSON(cl_dataset_train))

# Wait for TRAIN dataset
start = time.time()
while True:
    time.sleep(POLL_CREATE_DATASET_SEC)
    ds = rekognition.describe_dataset(DatasetArn=cl_dataset_train['DatasetArn'])
    status = ds['DatasetDescription']['Status']
    print("TRAIN dataset status:", status)
    if status not in ('CREATE_IN_PROGRESS',):
        break
    if time.time() - start > TIMEOUT_CREATE_DATASET:
        raise TimeoutError("Timeout waiting for TRAIN dataset creation.")
display(JSON(ds))

# -------------------------
# Create empty TEST dataset
# -------------------------
cl_dataset_test = rekognition.create_dataset(
    DatasetType='TEST',
    ProjectArn=cl_project['ProjectArn']
)
display(JSON(cl_dataset_test))

# Wait for TEST dataset
start = time.time()
while True:
    time.sleep(POLL_CREATE_DATASET_SEC)
    ds_test = rekognition.describe_dataset(DatasetArn=cl_dataset_test['DatasetArn'])
    status = ds_test['DatasetDescription']['Status']
    print("TEST dataset status:", status)
    if status not in ('CREATE_IN_PROGRESS',):
        break
    if time.time() - start > TIMEOUT_CREATE_DATASET:
        raise TimeoutError("Timeout waiting for TEST dataset creation.")
display(JSON(ds_test))

# -------------------------
# Distribute entries (split TRAIN → TRAIN/TEST)
# -------------------------
dist = rekognition.distribute_dataset_entries(
    Datasets=[{'Arn': cl_dataset_train['DatasetArn']},
              {'Arn': cl_dataset_test['DatasetArn']}]
)

# Wait for both to exit CREATE_IN_PROGRESS
start = time.time()
while True:
    time.sleep(POLL_CREATE_DATASET_SEC)
    ds_tr = rekognition.describe_dataset(DatasetArn=cl_dataset_train['DatasetArn'])
    ds_te = rekognition.describe_dataset(DatasetArn=cl_dataset_test['DatasetArn'])
    st_tr = ds_tr['DatasetDescription']['Status']
    st_te = ds_te['DatasetDescription']['Status']
    print("TRAIN status:", st_tr, "| TEST status:", st_te)
    if st_tr not in ('CREATE_IN_PROGRESS',) and st_te not in ('CREATE_IN_PROGRESS',):
        break
    if time.time() - start > TIMEOUT_CREATE_DATASET:
        raise TimeoutError("Timeout waiting for distribution to complete.")
display(JSON(ds_tr))
display(JSON(ds_te))

# -------------------------
# Train model
# -------------------------
model_version_name = f'model_v{int(time.time())}'
cl_train_model = rekognition.create_project_version(
    ProjectArn=cl_project['ProjectArn'],
    VersionName=model_version_name,
    OutputConfig={'S3Bucket': rek_cl_default_bucket, 'S3KeyPrefix': 'stanford_dog_dataset/model_train'}
)
display(JSON(cl_train_model))

# Wait for training
start = time.time()
while True:
    time.sleep(POLL_TRAIN_MODEL_SEC)
    mv = rekognition.describe_project_versions(
        ProjectArn=cl_project['ProjectArn'],
        VersionNames=[model_version_name]
    )
    st = mv['ProjectVersionDescriptions'][0]['Status']
    print("Training status:", st)
    if st not in ('TRAINING_IN_PROGRESS',):
        break
    if time.time() - start > TIMEOUT_TRAIN:
        raise TimeoutError("Timeout waiting for training.")
display(JSON(mv))

# Metrics
model_metrics = rekognition.describe_project_versions(
    ProjectArn=cl_project['ProjectArn'],
    VersionNames=[model_version_name]
)
print("F1 Score", model_metrics['ProjectVersionDescriptions'][0]['EvaluationResult']['F1Score'])

# Load evaluation summary JSON from S3
summary_obj = model_metrics['ProjectVersionDescriptions'][0]['EvaluationResult']['Summary']['S3Object']
content_object = s3_res.Object(summary_obj['Bucket'], summary_obj['Name'])
file_content = content_object.get()['Body'].read().decode('utf-8')
json_content = json.loads(file_content)
display(JSON(json_content))

# -------------------------
# Start model for inference
# -------------------------
start_model = rekognition.start_project_version(
    ProjectVersionArn=model_metrics['ProjectVersionDescriptions'][0]['ProjectVersionArn'],
    MinInferenceUnits=1
)
display(JSON(start_model))

# Wait for STARTED
start = time.time()
while True:
    time.sleep(POLL_START_MODEL_SEC)
    mstat = rekognition.describe_project_versions(
        ProjectArn=cl_project['ProjectArn'],
        VersionNames=[model_version_name]
    )
    st = mstat['ProjectVersionDescriptions'][0]['Status']
    print("Model status:", st)
    if st not in ('STARTING',):
        break
    if time.time() - start > TIMEOUT_START_STOP:
        raise TimeoutError("Timeout waiting for model to start.")
display(JSON(mstat))

# -------------------------
# Inference helpers
# -------------------------
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO, format="%(levelname)s: %(message)s")

def show_image(image, response):
    try:
        font = safe_truetype()
        font_size = 12
        line_width = 3
        img_width, img_height = image.size
        draw = ImageDraw.Draw(image)

        for custom_label in response.get('CustomLabels', []):
            confidence = int(round(custom_label.get('Confidence', 0), 0))
            label_text = f"{custom_label.get('Name','?')}:{confidence}%"

            # Draw boxes if present
            if 'Geometry' in custom_label and 'BoundingBox' in custom_label['Geometry']:
                box = custom_label['Geometry']['BoundingBox']
                left = img_width * box['Left']
                top = img_height * box['Top']
                width = img_width * box['Width']
                height = img_height * box['Height']

                points = (
                    (left, top),
                    (left + width, top),
                    (left + width, top + height),
                    (left, top + height),
                    (left, top)
                )
                draw.line(points, fill="limegreen", width=line_width)
                # text background
                tw, th = draw.textsize(label_text, font=font)
                draw.rectangle([(left + line_width, top + line_width),
                                (left + line_width + tw, top + line_width + th)], fill="black")
                draw.text((left + line_width, top + line_width), label_text, fill="limegreen", font=font)
            else:
                # image-level label
                draw.text((10, 10), label_text, fill="limegreen", font=font)

        display(image)

    except Exception as err:
        logger.error("show_image error: %s", err)
        raise

def analyze_s3_image(rek_client, s3_connection, model, bucket, photo, min_confidence):
    try:
        s3_object = s3_connection.Object(bucket, photo)
        s3_response = s3_object.get()
        stream = io.BytesIO(s3_response['Body'].read())
        image = Image.open(stream)

        image_type = Image.MIME.get(image.format, "")
        if image_type not in ("image/jpeg", "image/png"):
            raise ValueError(f"Invalid file format. Supply a jpeg or png: {photo}")

        response = rek_client.detect_custom_labels(
            Image={'S3Object': {'Bucket': bucket, 'Name': photo}},
            MinConfidence=min_confidence,
            ProjectVersionArn=model
        )

        show_image(image, response)
        return len(response.get('CustomLabels', []))

    except ClientError as err:
        logger.error("%s", err)
        raise

def analyze_rekcl_bb(bucket_nm, photos, modelarn, min_confidence=70):
    rek_client = mySession.client('rekognition', region_name=awsRegion)
    s3_connection = mySession.resource('s3', region_name=awsRegion)

    for photo in photos:
        count = analyze_s3_image(
            rek_client, s3_connection, modelarn, bucket_nm, photo, min_confidence
        )
        logger.info("Custom labels detected for %s: %s", photo, count)

# -------------------------
# Run inference on holdout images in S3
# -------------------------
holdout_photos = [
    f"stanford_dog_dataset/holdout/{f}"
    for f in listdir('./stanford_dog_dataset/holdout')
    if isfile(join('./stanford_dog_dataset/holdout', f)) and f.lower().endswith('.jpg')
]
model_arn = model_metrics['ProjectVersionDescriptions'][0]['ProjectVersionArn']

analyze_rekcl_bb(rek_cl_default_bucket, holdout_photos, model_arn, min_confidence=70)

# -------------------------
# Stop model (to stop billing)
# -------------------------
stop_model = rekognition.stop_project_version(
    ProjectVersionArn=model_arn
)
display(JSON(stop_model))

# Wait for STOPPED
start = time.time()
while True:
    time.sleep(POLL_START_MODEL_SEC)
    mstat = rekognition.describe_project_versions(
        ProjectArn=cl_project['ProjectArn'],
        VersionNames=[model_version_name]
    )
    st = mstat['ProjectVersionDescriptions'][0]['Status']
    print("Model status:", st)
    if st not in ('STOPPING',):
        break
    if time.time() - start > TIMEOUT_START_STOP:
        raise TimeoutError("Timeout waiting for model to stop.")
display(JSON(mstat))

print("✅ Done")
